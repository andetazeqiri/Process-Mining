{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlGgJqCW1rhW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZZ0P2mX2NbZ",
        "outputId": "d24d2ccc-33aa-400a-9f47-e54c49c88921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading event log data...\n",
            "Successfully loaded 75 events.\n",
            "Sample data:\n",
            "   CaseID                       Activity          InitialStatus  \\\n",
            "0       1       Access to the DAP portal                  Start   \n",
            "1       1      Selection of the position               Accessed   \n",
            "2       1  Start preparing the documents      Position Selected   \n",
            "3       1             Submit Application     Documents Prepared   \n",
            "4       1     Receiving the applications  Application Submitted   \n",
            "\n",
            "             FinalStatus                       ProcessFlow       Timestamp  \n",
            "0               Accessed                  Start of process  3/30/2025 8:00  \n",
            "1      Position Selected      Applicant selects a position  3/30/2025 8:05  \n",
            "2     Documents Prepared       Documents preparation phase  3/30/2025 8:30  \n",
            "3  Application Submitted         Submission of application  3/30/2025 9:00  \n",
            "4   Application Received  Institution receives application  3/30/2025 9:30  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Loading event log data...\")\n",
        "try:\n",
        "    event_log = pd.read_csv('proceset.csv')\n",
        "    print(f\"Successfully loaded {len(event_log)} events.\")\n",
        "    print(\"Sample data:\")\n",
        "    print(event_log.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: proceset.csv not found. Using sample data for demonstration.\")\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    case_ids = [f\"CASE_{i}\" for i in range(1, 101)]\n",
        "    activities = [\"Register\", \"Review\", \"Validate\", \"Approve\", \"Reject\", \"Notify\"]\n",
        "\n",
        "    data = []\n",
        "    for case_id in case_ids:\n",
        "        \n",
        "        num_activities = np.random.randint(3, 8)\n",
        "        \n",
        "        start_time = pd.Timestamp('2025-01-01') + pd.Timedelta(days=np.random.randint(0, 120))\n",
        "\n",
        "        \n",
        "        for i in range(num_activities):\n",
        "            activity = np.random.choice(activities)\n",
        "            \n",
        "            timestamp = start_time + pd.Timedelta(days=np.random.randint(0, 5))\n",
        "            resource = f\"RESOURCE_{np.random.randint(1, 6)}\"\n",
        "            start_time = timestamp  \n",
        "\n",
        "            data.append({\n",
        "                'case_id': case_id,\n",
        "                'activity': activity,\n",
        "                'timestamp': timestamp,\n",
        "                'resource': resource\n",
        "            })\n",
        "\n",
        "    event_log = pd.DataFrame(data)\n",
        "    event_log['timestamp'] = pd.to_datetime(event_log['timestamp'])\n",
        "    print(\"Created sample event log data:\")\n",
        "    print(event_log.head())\n",
        "\n",
        "\n",
        "if not pd.api.types.is_datetime64_any_dtype(event_log['Timestamp']):\n",
        "    event_log['Timestamp'] = pd.to_datetime(event_log['Timestamp'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hpOP5Zi23IC",
        "outputId": "dc7bb1ae-01ec-4800-f0dd-897c938cc1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting case-level features...\n",
            "Created case features:\n",
            "   CaseID  duration  num_events  num_unique_activities  num_resources  \\\n",
            "0       1  3.333333          12                     12              0   \n",
            "1       2  0.107639           7                      7              0   \n",
            "2       3  0.111111           8                      8              0   \n",
            "3       4  3.291667          12                     12              0   \n",
            "4       5  1.125000          11                     10              0   \n",
            "\n",
            "   avg_time_between  has_reject  activity_transitions  \n",
            "0          0.303030           0                    11  \n",
            "1          0.017940           0                     6  \n",
            "2          0.015873           0                     7  \n",
            "3          0.299242           0                    11  \n",
            "4          0.112500           0                    10  \n",
            "Total cases: 8\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nExtracting case-level features...\")\n",
        "\n",
        "\n",
        "case_features = []\n",
        "\n",
        "for case_id, case_df in event_log.groupby('CaseID'):\n",
        "    \n",
        "    case_df = case_df.sort_values('Timestamp')\n",
        "\n",
        "    \n",
        "    start_time = case_df['Timestamp'].min()\n",
        "    end_time = case_df['Timestamp'].max()\n",
        "\n",
        "    \n",
        "    duration = (end_time - start_time).total_seconds() / (60*60*24)  \n",
        "\n",
        "    \n",
        "    num_events = len(case_df)\n",
        "\n",
        "    \n",
        "    num_unique_activities = case_df['Activity'].nunique()\n",
        "\n",
        "    \n",
        "    num_resources = case_df['resource'].nunique() if 'resource' in case_df.columns else 0\n",
        "\n",
        "   \n",
        "    if num_events > 1:\n",
        "        time_diffs = []\n",
        "        timestamps = case_df['Timestamp'].tolist()\n",
        "        for i in range(1, len(timestamps)):\n",
        "            diff = (timestamps[i] - timestamps[i-1]).total_seconds() / (60*60*24)\n",
        "            time_diffs.append(diff)\n",
        "        avg_time_between = sum(time_diffs) / len(time_diffs)\n",
        "    else:\n",
        "        avg_time_between = 0\n",
        "\n",
        "  \n",
        "    has_reject = 1 if \"Reject\" in case_df['Activity'].values else 0\n",
        "\n",
        "    \n",
        "    activity_transitions = 0\n",
        "    if num_events > 1:\n",
        "        activities = case_df['Activity'].tolist()\n",
        "        for i in range(1, len(activities)):\n",
        "            if activities[i] != activities[i-1]:\n",
        "                activity_transitions += 1\n",
        "\n",
        "   \n",
        "    case_features.append({\n",
        "        'CaseID': case_id,\n",
        "        'duration': duration,\n",
        "        'num_events': num_events,\n",
        "        'num_unique_activities': num_unique_activities,\n",
        "        'num_resources': num_resources,\n",
        "        'avg_time_between': avg_time_between,\n",
        "        'has_reject': has_reject,\n",
        "        'activity_transitions': activity_transitions\n",
        "    })\n",
        "\n",
        "\n",
        "case_features_df = pd.DataFrame(case_features)\n",
        "print(\"Created case features:\")\n",
        "print(case_features_df.head())\n",
        "print(f\"Total cases: {len(case_features_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIzlh2CTCFX5",
        "outputId": "55b45f46-4946-47a8-933e-38cc6a6c0128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated optimal number of clusters (k): 6\n",
            "Applying K-Means with k=6...\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "features = case_features_df.select_dtypes(include=[np.number])\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "max_k = min(10, X_scaled.shape[0])\n",
        "k_range = range(1, max_k + 1)\n",
        "\n",
        "inertia = []\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, inertia, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.grid(True)\n",
        "plt.savefig('elbow_method.png')\n",
        "plt.close()\n",
        "\n",
        "if len(inertia) > 2:\n",
        "    inertia_diff = np.diff(inertia)\n",
        "    inertia_diff2 = np.diff(inertia_diff)\n",
        "    optimal_k = np.argmin(np.abs(inertia_diff2)) + 2\n",
        "else:\n",
        "    optimal_k = 1\n",
        "\n",
        "print(f\"Estimated optimal number of clusters (k): {optimal_k}\")\n",
        "\n",
        "print(f\"Applying K-Means with k={optimal_k}...\")\n",
        "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters = final_kmeans.fit_predict(X_scaled)\n",
        "\n",
        "case_features_df['cluster'] = clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzm2DDf_3eTL",
        "outputId": "72b63603-9a78-4ada-ff7e-6a869946e8a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated optimal number of clusters (k): 6\n",
            "Applying K-Means with k=6...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "max_k = min(10, X_scaled.shape[0])  \n",
        "k_range = range(1, max_k + 1)\n",
        "\n",
        "inertia = []\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, inertia, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.grid(True)\n",
        "plt.savefig('elbow_method.png')\n",
        "plt.close()\n",
        "\n",
        "\n",
        "if len(inertia) > 2:\n",
        "    inertia_diff = np.diff(inertia)\n",
        "    inertia_diff2 = np.diff(inertia_diff)\n",
        "    optimal_k = np.argmin(np.abs(inertia_diff2)) + 2 \n",
        "else:\n",
        "    optimal_k = 1  \n",
        "\n",
        "print(f\"Estimated optimal number of clusters (k): {optimal_k}\")\n",
        "\n",
        "\n",
        "print(f\"Applying K-Means with k={optimal_k}...\")\n",
        "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters = final_kmeans.fit_predict(X_scaled)\n",
        "\n",
        "\n",
        "case_features_df['cluster'] = clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZrPXyaKCbBg",
        "outputId": "b3522faa-ae3f-42d1-c41d-6a8df53ba385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cluster centers (mean values):\n",
            "         duration  num_events  num_unique_activities  avg_time_between\n",
            "cluster                                                               \n",
            "0        0.109375         7.5                    7.5          0.016906\n",
            "1        3.312500        12.0                   12.0          0.301136\n",
            "2        0.006944         3.0                    3.0          0.003472\n",
            "3        1.125000        11.0                   10.0          0.112500\n",
            "4        2.166667        10.0                   10.0          0.240741\n",
            "5        3.125000        12.0                   12.0          0.284091\n"
          ]
        }
      ],
      "source": [
        "\n",
        "features = ['duration', 'num_events', 'num_unique_activities', 'avg_time_between']\n",
        "\n",
        "\n",
        "cluster_stats = case_features_df.groupby('cluster')[features].mean()\n",
        "print(\"\\nCluster centers (mean values):\")\n",
        "print(cluster_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "8-KDyzQD38Pw",
        "outputId": "8303210a-a5ff-420b-df3c-81ecae29f25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing cluster characteristics...\n",
            "\n",
            "Cluster centers (mean values):\n",
            "         duration  num_events  num_unique_activities  avg_time_between\n",
            "cluster                                                               \n",
            "0        0.109375         7.5                    7.5          0.016906\n",
            "1        3.312500        12.0                   12.0          0.301136\n",
            "2        0.006944         3.0                    3.0          0.003472\n",
            "3        1.125000        11.0                   10.0          0.112500\n",
            "4        2.166667        10.0                   10.0          0.240741\n",
            "5        3.125000        12.0                   12.0          0.284091\n",
            "\n",
            "Number of cases in each cluster:\n",
            "cluster\n",
            "0    2\n",
            "1    2\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "5    1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "print(\"\\nAnalyzing cluster characteristics...\")\n",
        "\n",
        "\n",
        "cluster_stats = case_features_df.groupby('cluster')[features].mean()\n",
        "print(\"\\nCluster centers (mean values):\")\n",
        "print(cluster_stats)\n",
        "\n",
        "\n",
        "cluster_counts = case_features_df['cluster'].value_counts().sort_index()\n",
        "print(\"\\nNumber of cases in each cluster:\")\n",
        "print(cluster_counts)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "\n",
        "feature1 = 'duration'  # x-axis\n",
        "feature2 = 'num_events'  # y-axis\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(\n",
        "    case_features_df[feature1],\n",
        "    case_features_df[feature2],\n",
        "    c=case_features_df['cluster'],\n",
        "    cmap='viridis',\n",
        "    alpha=0.7,\n",
        "    s=100\n",
        ")\n",
        "\n",
        "plt.colorbar(scatter, label='Cluster')\n",
        "plt.xlabel(feature1)\n",
        "plt.ylabel(feature2)\n",
        "plt.title(f'K-Means Clustering of Process Cases (k={optimal_k})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('cluster_visualization_2d.png')\n",
        "plt.close()\n",
        "\n",
        "vis_features = ['duration', 'num_events', 'num_unique_activities', 'avg_time_between']\n",
        "vis_df = case_features_df[vis_features + ['cluster']].copy()\n",
        "\n",
        "\n",
        "vis_df['cluster'] = vis_df['cluster'].astype('category')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "pair_plot = sns.pairplot(vis_df, hue='cluster', palette='viridis', corner=True)\n",
        "pair_plot.fig.suptitle(f'Pairwise Relationships in Clusters (k={optimal_k})', y=1.02)\n",
        "plt.savefig('cluster_pairplot.png')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cluster_stats, annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "plt.title(f'Cluster Centers Heatmap (k={optimal_k})')\n",
        "plt.savefig('cluster_centers_heatmap.png')\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp19QAB-4Py6",
        "outputId": "cd0a09c3-dbeb-4aea-e557-d0bf3539dfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detailed analysis of each cluster:\n",
            "\n",
            "Cluster 0 Analysis:\n",
            "  Number of cases: 2\n",
            "  Percentage of total: 25.00%\n",
            "  duration: mean=0.11, std=0.00\n",
            "  num_events: mean=7.50, std=0.71\n",
            "  num_unique_activities: mean=7.50, std=0.71\n",
            "  avg_time_between: mean=0.02, std=0.00\n",
            "  Sample cases: 2, 3\n",
            "\n",
            "Cluster 1 Analysis:\n",
            "  Number of cases: 2\n",
            "  Percentage of total: 25.00%\n",
            "  duration: mean=3.31, std=0.03\n",
            "  num_events: mean=12.00, std=0.00\n",
            "  num_unique_activities: mean=12.00, std=0.00\n",
            "  avg_time_between: mean=0.30, std=0.00\n",
            "  Sample cases: 1, 4\n",
            "\n",
            "Cluster 2 Analysis:\n",
            "  Number of cases: 1\n",
            "  Percentage of total: 12.50%\n",
            "  duration: mean=0.01, std=nan\n",
            "  num_events: mean=3.00, std=nan\n",
            "  num_unique_activities: mean=3.00, std=nan\n",
            "  avg_time_between: mean=0.00, std=nan\n",
            "  Sample cases: 8\n",
            "\n",
            "Cluster 3 Analysis:\n",
            "  Number of cases: 1\n",
            "  Percentage of total: 12.50%\n",
            "  duration: mean=1.12, std=nan\n",
            "  num_events: mean=11.00, std=nan\n",
            "  num_unique_activities: mean=10.00, std=nan\n",
            "  avg_time_between: mean=0.11, std=nan\n",
            "  Sample cases: 5\n",
            "\n",
            "Cluster 4 Analysis:\n",
            "  Number of cases: 1\n",
            "  Percentage of total: 12.50%\n",
            "  duration: mean=2.17, std=nan\n",
            "  num_events: mean=10.00, std=nan\n",
            "  num_unique_activities: mean=10.00, std=nan\n",
            "  avg_time_between: mean=0.24, std=nan\n",
            "  Sample cases: 6\n",
            "\n",
            "Cluster 5 Analysis:\n",
            "  Number of cases: 1\n",
            "  Percentage of total: 12.50%\n",
            "  duration: mean=3.12, std=nan\n",
            "  num_events: mean=12.00, std=nan\n",
            "  num_unique_activities: mean=12.00, std=nan\n",
            "  avg_time_between: mean=0.28, std=nan\n",
            "  Sample cases: 7\n",
            "\n",
            "Adding cluster information to the original event log...\n",
            "Enhanced event log saved as 'event_log_with_clusters.csv'\n",
            "Case features with clusters saved as 'case_features_with_clusters.csv'\n",
            "\n",
            "Clustering analysis complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nDetailed analysis of each cluster:\")\n",
        "\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_cases = case_features_df[case_features_df['cluster'] == cluster_id]\n",
        "    print(f\"\\nCluster {cluster_id} Analysis:\")\n",
        "    print(f\"  Number of cases: {len(cluster_cases)}\")\n",
        "    print(f\"  Percentage of total: {len(cluster_cases) / len(case_features_df) * 100:.2f}%\")\n",
        "\n",
        "    \n",
        "    for feature in features:\n",
        "        mean_val = cluster_cases[feature].mean()\n",
        "        std_val = cluster_cases[feature].std()\n",
        "        print(f\"  {feature}: mean={mean_val:.2f}, std={std_val:.2f}\")\n",
        "\n",
        "    \n",
        "    sample_cases = cluster_cases['CaseID'].values[:5]\n",
        "    print(f\"  Sample cases: {', '.join(map(str, sample_cases))}\")\n",
        "\n",
        "print(\"\\nAdding cluster information to the original event log...\")\n",
        "\n",
        "case_cluster_map = dict(zip(case_features_df['CaseID'], case_features_df['cluster']))\n",
        "\n",
        "\n",
        "event_log['cluster'] = event_log['CaseID'].map(case_cluster_map)\n",
        "\n",
        "\n",
        "event_log.to_csv('event_log_with_clusters.csv', index=False)\n",
        "print(\"Enhanced event log saved as 'event_log_with_clusters.csv'\")\n",
        "\n",
        "\n",
        "case_features_df.to_csv('case_features_with_clusters.csv', index=False)\n",
        "print(\"Case features with clusters saved as 'case_features_with_clusters.csv'\")\n",
        "\n",
        "print(\"\\nClustering analysis complete!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
